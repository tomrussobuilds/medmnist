{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Orchard ML Quick Start: MiniCNN on BloodMNIST (CPU)\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tomrussobuilds/orchard-ml/blob/main/notebooks/01_quickstart_bloodmnist_cpu.ipynb)\n\nThis notebook demonstrates the core Orchard ML training workflow using a lightweight setup that runs entirely on **CPU**:\n\n- **Dataset**: [BloodMNIST](https://medmnist.com/) (28x28 RGB, 8 blood cell classes)\n- **Model**: MiniCNN (~94K parameters)\n- **Time**: ~5-10 minutes on Colab CPU\n\n### What you'll learn\n1. How Orchard ML uses YAML configs to drive the entire training pipeline\n2. How to launch training with `forge.py`\n3. How to explore generated artifacts (metrics, plots, reports)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Clone the repository and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n%cd /content\nif not os.path.isdir(\"orchard-ml\"):\n    !git clone --depth 1 https://github.com/tomrussobuilds/orchard-ml.git\n\n%cd /content/orchard-ml\n!git pull --ff-only\n%pip install -q -r requirements.txt"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Configuration\n\nOrchard ML is entirely **configuration-driven** — a single YAML file controls dataset, model, training, augmentation, evaluation, and export.\n\nWe write a Colab-friendly config based on `recipes/config_mini_cnn.yaml`, with reduced epochs (15) and tracking disabled (no MLflow needed in Colab)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile colab_bloodmnist_cpu.yaml\n",
    "# BloodMNIST CPU Quick Start — Colab-optimized config\n",
    "\n",
    "dataset:\n",
    "  name: \"bloodmnist\"\n",
    "  data_root: ./dataset\n",
    "  resolution: 28\n",
    "  force_rgb: true\n",
    "  use_weighted_sampler: true\n",
    "\n",
    "architecture:\n",
    "  name: \"mini_cnn\"\n",
    "  pretrained: false\n",
    "  dropout: 0.3\n",
    "\n",
    "training:\n",
    "  seed: 42\n",
    "  batch_size: 64\n",
    "  learning_rate: 0.01\n",
    "  weight_decay: 5e-4\n",
    "  momentum: 0.9\n",
    "  min_lr: 1e-6\n",
    "  mixup_alpha: 0.2\n",
    "  label_smoothing: 0.1\n",
    "  epochs: 15\n",
    "  patience: 10\n",
    "  grad_clip: 1.0\n",
    "  mixup_epochs: 0\n",
    "  scheduler_type: \"cosine\"\n",
    "  cosine_fraction: 0.8\n",
    "  scheduler_patience: 5\n",
    "  scheduler_factor: 0.1\n",
    "  step_size: 20\n",
    "  use_amp: false\n",
    "  use_tta: false\n",
    "  criterion_type: \"cross_entropy\"\n",
    "  weighted_loss: false\n",
    "  focal_gamma: 2.0\n",
    "\n",
    "augmentation:\n",
    "  hflip: 0.5\n",
    "  rotation_angle: 15\n",
    "  jitter_val: 0.3\n",
    "  min_scale: 0.9\n",
    "  tta_translate: 0.5\n",
    "  tta_scale: 1.02\n",
    "  tta_blur_sigma: 0.1\n",
    "\n",
    "hardware:\n",
    "  device: \"auto\"\n",
    "\n",
    "telemetry:\n",
    "  output_dir: ./outputs\n",
    "  log_level: \"INFO\"\n",
    "  log_interval: 50\n",
    "\n",
    "evaluation:\n",
    "  batch_size: 256\n",
    "  n_samples: 16\n",
    "  fig_dpi: 200\n",
    "  cmap_confusion: Blues\n",
    "  plot_style: seaborn-v0_8-muted\n",
    "  grid_cols: 4\n",
    "  fig_size_predictions: [12, 8]\n",
    "  report_format: xlsx\n",
    "  save_confusion_matrix: true\n",
    "  save_predictions_grid: true\n",
    "\n",
    "tracking:\n",
    "  enabled: false\n",
    "\n",
    "export:\n",
    "  format: onnx\n",
    "  opset_version: 18\n",
    "  validate_export: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train\n",
    "\n",
    "Launch the full pipeline: dataset download, training for 15 epochs, evaluation, and ONNX export.\n",
    "\n",
    "The config uses `batch_size: 64` and `epochs: 15` to keep runtime under 15 minutes on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python forge.py --config colab_bloodmnist_cpu.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Explore Results\n\nOrchard ML saves all artifacts to a timestamped directory under `outputs/`. Let's inspect what was generated."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Find the latest run directory\n",
    "run_dirs = sorted(glob.glob(\"outputs/*/\"))\n",
    "latest_run = run_dirs[-1]\n",
    "print(f\"Latest run: {latest_run}\")\n",
    "\n",
    "# List all generated artifacts\n",
    "for root, dirs, files in os.walk(latest_run):\n",
    "    level = root.replace(latest_run, \"\").count(os.sep)\n",
    "    indent = \"  \" * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    sub_indent = \"  \" * (level + 1)\n",
    "    for file in sorted(files):\n",
    "        size = os.path.getsize(os.path.join(root, file))\n",
    "        print(f\"{sub_indent}{file} ({size / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "# Display confusion matrix\n",
    "cm_files = glob.glob(f\"{latest_run}/figures/confusion_matrix*.png\")\n",
    "if cm_files:\n",
    "    print(\"Confusion Matrix:\")\n",
    "    display(Image(filename=cm_files[0], width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display predictions grid\n",
    "pred_files = glob.glob(\n",
    "    f\"{latest_run}/figures/sample_predictions*.png\"\n",
    ")\n",
    "if pred_files:\n",
    "    print(\"Sample Predictions:\")\n",
    "    display(Image(filename=pred_files[0], width=700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Show the saved config for full reproducibility\nimport yaml\n\nconfig_files = glob.glob(f\"{latest_run}/reports/config*.yaml\")\nif config_files:\n    with open(config_files[0]) as f:\n        saved_cfg = yaml.safe_load(f)\n    print(\"Saved configuration (full reproducibility snapshot):\")\n    print(yaml.dump(saved_cfg, default_flow_style=False, sort_keys=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Next Steps\n\n- **GPU training**: Switch to a GPU runtime and try `recipes/config_efficientnet_b0.yaml` for 224x224 resolution\n- **Hyperparameter search**: See [02_galaxy10_optuna_model_search.ipynb](./02_galaxy10_optuna_model_search.ipynb) for Optuna-powered optimization with automatic model selection\n- **Custom datasets**: Check the [Configuration Guide](https://github.com/tomrussobuilds/orchard-ml/blob/main/docs/guide/CONFIGURATION.md) for adding your own data\n- **Full recipe catalog**: Browse all 15 pre-configured recipes in the [recipes/](https://github.com/tomrussobuilds/orchard-ml/tree/main/recipes) directory"
  }
 ],
 "metadata": {
  "accelerator": "None",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}